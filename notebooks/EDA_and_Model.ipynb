{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94058063",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Install and import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "# Cell 2: Load or create dataset\n",
    "# Download from: https://www.kaggle.com/datasets/aljaroudi/student-performance-dataset\n",
    "# Or create synthetic data:\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'attendance': np.random.uniform(60, 100, n_samples),\n",
    "    'internal_marks': np.random.uniform(30, 90, n_samples),\n",
    "    'study_hours': np.random.uniform(0, 8, n_samples),\n",
    "    'backlogs': np.random.randint(0, 5, n_samples),\n",
    "    'participation': np.random.uniform(1, 5, n_samples),\n",
    "    'pass': np.random.randint(0, 2, n_samples)\n",
    "})\n",
    "\n",
    "print(data.head())\n",
    "print(data.describe())\n",
    "\n",
    "# Cell 3: Data preprocessing\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Feature engineering\n",
    "X = data[['attendance', 'internal_marks', 'study_hours', 'backlogs', 'participation']]\n",
    "y = data['pass']\n",
    "\n",
    "# Handle missing values (if any)\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "# Cell 4: Train multiple models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'model': model\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  F1-Score: {f1:.4f}\")\n",
    "    print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Cell 5: Model comparison\n",
    "best_model_name = max(results, key=lambda x: results[x]['accuracy'])\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "\n",
    "# Cell 6: Evaluate best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {results[best_model_name][\"roc_auc\"]:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Cell 7: Save model and preprocessor\n",
    "with open('../backend/models/model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "with open('../backend/models/preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Model and preprocessor saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
